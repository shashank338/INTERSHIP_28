{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf459e5d",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "\n",
    "* have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "  jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "21010406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITELS</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>EXPERIENCE_REQUIRED</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>NXP Semiconductors</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY GDS Data Analyst-Finland based project</td>\n",
       "      <td>EY</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Data and Analytics</td>\n",
       "      <td>Intel</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst (CSD)</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Data Science, 3 To 5 Years</td>\n",
       "      <td>Rise Finconnect Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAS/SQL - Healthcare Data Analyst - Bangalore</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business &amp; Data Analyst - Alteryx (London)</td>\n",
       "      <td>Imaginative Brains LLP</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data analyst / Data scientist, AVP</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB TITELS  \\\n",
       "1                               Business Data Analyst   \n",
       "2           EY GDS Data Analyst-Finland based project   \n",
       "3                   Data Analyst - Data and Analytics   \n",
       "4                                  Data Analyst (CSD)   \n",
       "5           Data Analyst - Data Science, 3 To 5 Years   \n",
       "6                     Data Analyst / Business Analyst   \n",
       "7       SAS/SQL - Healthcare Data Analyst - Bangalore   \n",
       "8          Business & Data Analyst - Alteryx (London)   \n",
       "9   data analyst/ data analytics / Business analys...   \n",
       "10                 Data analyst / Data scientist, AVP   \n",
       "\n",
       "                       COMPANY NAME EXPERIENCE_REQUIRED  \\\n",
       "1                NXP Semiconductors             2-5 Yrs   \n",
       "2                                EY             0-1 Yrs   \n",
       "3                             Intel             3-6 Yrs   \n",
       "4                           Siemens             2-6 Yrs   \n",
       "5   Rise Finconnect Private Limited             2-6 Yrs   \n",
       "6                METRO Cash & Carry             3-8 Yrs   \n",
       "7                           Genpact            7-10 Yrs   \n",
       "8            Imaginative Brains LLP            5-10 Yrs   \n",
       "9     Leading US MNC into Analytics             2-7 Yrs   \n",
       "10                    Deutsche Bank            6-11 Yrs   \n",
       "\n",
       "                                             LOCATION  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3                                 Bangalore/Bengaluru  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                                 Bangalore/Bengaluru  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8   Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "9   Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...  \n",
       "10                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#  finding element for job search bar\n",
    "search_field_loc=driver.find_element_by_class_name(\"suggestor-input\")#job search bar\n",
    "search_field_loc.send_keys(\"Data Analyst\")\n",
    "# here we use to select the location\n",
    "search_field_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_field_location.send_keys(\"Bangalore\") \n",
    "\n",
    "#clicking the search button \n",
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "job_titles=[]# creating empty list for store \n",
    "company_names=[]# creating empty list for store \n",
    "locations_list=[]# creating empty list for store \n",
    "experience_list=[]# creating empty list for store \n",
    "\n",
    "#lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "job_titles[0:10]\n",
    "\n",
    "\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in companies_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "company_names[0:10]\n",
    "\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "experience_list[0:10]#using range to print only top 10 results\n",
    "\n",
    "\n",
    "\n",
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "locations_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "\n",
    "for i in locations_tags:\n",
    "    location=i.text\n",
    "    locations_list.append(location)\n",
    "locations_list[0:10]\n",
    "\n",
    "\n",
    "# creating the dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['JOB TITELS']=job_titles[0:10]\n",
    "jobs['COMPANY NAME']=company_names[0:10]\n",
    "jobs['EXPERIENCE_REQUIRED']=experience_list[0:10]\n",
    "jobs['LOCATION']=locations_list[0:10]\n",
    "jobs.index+=1\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b099f64",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    " * have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "   This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b1185b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITELS</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>EXPERIENCE REQUIRED</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>9-13 Yrs</td>\n",
       "      <td>Noida, Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Technologist Vacancy</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Opening with Wipro For Data Scientist posi...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA Scientist with Fraud Analytics Experience</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB TITELS  \\\n",
       "1                  Data Science - Engineering Manager   \n",
       "2                             AI Technologist Vacancy   \n",
       "3   Job Opening with Wipro For Data Scientist posi...   \n",
       "4      DATA Scientist with Fraud Analytics Experience   \n",
       "5                                      Data Scientist   \n",
       "6                                      Data Scientist   \n",
       "7                                      Data Scientist   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                 COMPANY NAME EXPERIENCE REQUIRED  \\\n",
       "1                       Paytm            9-13 Yrs   \n",
       "2                       Wipro            6-11 Yrs   \n",
       "3                       Wipro             2-7 Yrs   \n",
       "4   Concentrix Daksh Services             2-4 Yrs   \n",
       "5           Applied Materials            7-10 Yrs   \n",
       "6           Applied Materials            7-10 Yrs   \n",
       "7           Applied Materials            7-10 Yrs   \n",
       "8           Applied Materials            7-10 Yrs   \n",
       "9           Applied Materials            7-10 Yrs   \n",
       "10          Applied Materials            7-10 Yrs   \n",
       "\n",
       "                                             LOCATION  \n",
       "1                  Noida, Mumbai, Bangalore/Bengaluru  \n",
       "2   Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "3   Kolkata, Hyderabad/Secunderabad, Chennai, Bang...  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                                 Bangalore/Bengaluru  \n",
       "6                                 Bangalore/Bengaluru  \n",
       "7                                 Bangalore/Bengaluru  \n",
       "8                                 Bangalore/Bengaluru  \n",
       "9                                 Bangalore/Bengaluru  \n",
       "10                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#  finding element for job search bar\n",
    "search_field_loc=driver.find_element_by_class_name(\"suggestor-input\")#job search bar\n",
    "search_field_loc.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_field_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_field_location.send_keys(\"Bangalore\") \n",
    "\n",
    "#clicking the search button \n",
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "job_titles=[]\n",
    "company_names=[]\n",
    "locations_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "#lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "job_titles[0:10]\n",
    "\n",
    "\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in companies_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "company_names[0:10]\n",
    "\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "experience_list[0:10]#using range to print only top 10 results\n",
    "\n",
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "locations_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "\n",
    "for i in locations_tags:\n",
    "    location=i.text\n",
    "    locations_list.append(location)\n",
    "locations_list[0:10]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# creating the dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['JOB TITELS']=job_titles[0:10]\n",
    "jobs['COMPANY NAME']=company_names[0:10]\n",
    "jobs['EXPERIENCE REQUIRED']=experience_list[0:10]\n",
    "jobs['LOCATION']=locations_list[0:10]\n",
    "jobs.index+=1\n",
    "jobs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c596d",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "        \n",
    "* You have to use the location and salary filter.\n",
    "* You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "* You have to scrape the job-title, job-location, company name, experience required.\n",
    "* The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3bbf7717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITELS</th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>EXPERIENCE REQUIRED</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Opening with Wipro For Data Scientist posi...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine learning AI</td>\n",
       "      <td>Teq Analytics</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist -Machine Learning with Python</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SS Supply Chain Solutions Pvt. Ltd. (3SC)</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Internet Jobs - II</td>\n",
       "      <td>Jobs Territory</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning Engineer | Data Engineer | Da...</td>\n",
       "      <td>Tidyquant (OPC) Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Delhi / NCR(Sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dot Net Developer</td>\n",
       "      <td>Nibha Infotech Private Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB TITELS  \\\n",
       "1   Job Opening with Wipro For Data Scientist posi...   \n",
       "2                Data Scientist - Machine learning AI   \n",
       "3        Data Scientist -Machine Learning with Python   \n",
       "4                                      Data Scientist   \n",
       "5                      Data Scientist - MIND Infotech   \n",
       "6                      Data Scientist - MIND Infotech   \n",
       "7               Data Scientist - Predictive Analytics   \n",
       "8                 Data Scientist - Internet Jobs - II   \n",
       "9   Machine Learning Engineer | Data Engineer | Da...   \n",
       "10                                  Dot Net Developer   \n",
       "\n",
       "                                 COMPANY NAME EXPERIENCE REQUIRED  \\\n",
       "1                                       Wipro             2-7 Yrs   \n",
       "2                               Teq Analytics             3-8 Yrs   \n",
       "3                                     Genpact             1-4 Yrs   \n",
       "4   SS Supply Chain Solutions Pvt. Ltd. (3SC)             2-5 Yrs   \n",
       "5    MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             4-8 Yrs   \n",
       "6    MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             4-8 Yrs   \n",
       "7                                Confidential             1-6 Yrs   \n",
       "8                              Jobs Territory             3-6 Yrs   \n",
       "9             Tidyquant (OPC) Private Limited             1-3 Yrs   \n",
       "10             Nibha Infotech Private Limited             3-8 Yrs   \n",
       "\n",
       "                                             LOCATION  \n",
       "1   Kolkata, Hyderabad/Secunderabad, Chennai, Bang...  \n",
       "2   Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "3     Noida, New Delhi, Gurgaon/Gurugram, Delhi / NCR  \n",
       "4         Pune, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "5                                               Noida  \n",
       "6                                               Noida  \n",
       "7   Noida, Mumbai, Chandigarh, Hyderabad/Secundera...  \n",
       "8   Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "9   Chennai, Bangalore/Bengaluru, Delhi / NCR(Sect...  \n",
       "10                      Gurgaon/Gurugram, Delhi / NCR  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "#opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#  finding element for job search bar\n",
    "search_field_loc=driver.find_element_by_class_name(\"suggestor-input\")#job search bar\n",
    "search_field_loc.send_keys(\"Data Scientist\")\n",
    "\n",
    "#clicking the search button \n",
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "\n",
    "more_button=driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[5]/a')\n",
    "more_button.click() # used to in filter to open the more in location \n",
    "select_button=driver.find_element_by_xpath('//*[@id=\"tooltip\"]/div[2]/div[3]/label/p/span[1]')\n",
    "select_button.click() # Here we used to selecting the Delhi/NCR\n",
    "time.sleep(5)\n",
    "\n",
    "more_button=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[5]/a/span')\n",
    "more_button.click()# used to in filter to open the more in salary\n",
    "select_button=driver.find_element_by_xpath('//*[@id=\"tooltip\"]/div[2]/div[2]/label/p/span[1]')\n",
    "select_button.click()# Here we used to selecting 3.6laks package \n",
    "time.sleep(5)\n",
    "\n",
    "job_titles=[]\n",
    "company_names=[]\n",
    "locations_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "#lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "job_titles[0:10]\n",
    "\n",
    "\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in companies_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "company_names[0:10]\n",
    "\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "experience_list[0:10]#using range to print only top 10 results\n",
    "\n",
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "locations_tags[0:10] #using range to print only top 10 results\n",
    "\n",
    "for i in locations_tags:\n",
    "    location=i.text\n",
    "    locations_list.append(location)\n",
    "locations_list[0:10]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# creating the dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['JOB TITELS']=job_titles[0:10]\n",
    "jobs['COMPANY NAME']=company_names[0:10]\n",
    "jobs['EXPERIENCE REQUIRED']=experience_list[0:10]\n",
    "jobs['LOCATION']=locations_list[0:10]\n",
    "jobs.index+=1\n",
    "jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ecc0b",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "* The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9ad7f10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANDS</th>\n",
       "      <th>PRODUCT DESCRIPTIONS</th>\n",
       "      <th>PRICES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Oval, Aviator Sunglasses (60)</td>\n",
       "      <td>₹1,909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (Fr...</td>\n",
       "      <td>₹525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Clubmaster Sunglasses (51)</td>\n",
       "      <td>₹236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection, Riding Glasses Aviator Sunglass...</td>\n",
       "      <td>₹415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection, Gradient Butterfly Sunglasses (62)</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Oval, Aviator Sunglasses (59)</td>\n",
       "      <td>₹415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (57)</td>\n",
       "      <td>₹1,007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection, Polarized Rectangular Sunglasse...</td>\n",
       "      <td>₹13,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Polarized Wrap-around, Sports S...</td>\n",
       "      <td>₹335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BRANDS                               PRODUCT DESCRIPTIONS   PRICES\n",
       "1       LIZA ANGEL        UV Protection Oval, Aviator Sunglasses (60)   ₹1,909\n",
       "2    VINCENT CHASE  Polarized, UV Protection Sports Sunglasses (Fr...     ₹525\n",
       "3               Mi               Polarized Clubmaster Sunglasses (51)     ₹236\n",
       "4             SRPM  UV Protection, Riding Glasses Aviator Sunglass...     ₹415\n",
       "5        Elligator  UV Protection, Gradient Butterfly Sunglasses (62)     ₹359\n",
       "..             ...                                                ...      ...\n",
       "96       ROYAL SON        UV Protection Oval, Aviator Sunglasses (59)     ₹415\n",
       "97          AISLIN   UV Protection, Gradient Wayfarer Sunglasses (57)   ₹1,007\n",
       "98       Rich Club  UV Protection, Polarized Rectangular Sunglasse...  ₹13,199\n",
       "99          GANSTA  UV Protection, Polarized Wrap-around, Sports S...     ₹335\n",
       "100      ROYAL SON  UV Protection Retro Square Sunglasses (Free Size)     ₹354\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#opening up flipkart.com website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# if its asked email and phone number lets exit from that \n",
    "exit_button=driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "exit_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#  finding element for job search bar\n",
    "search_field_loc=driver.find_element_by_class_name(\"_3704LK\")#job search bar\n",
    "search_field_loc.send_keys(\"sunglasses\")\n",
    "\n",
    "#clicking the search button \n",
    "search_button=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "Product_Brands=[] # creating empty list to store the Brands\n",
    "Product_Prices=[] # creating empty list to store the prices \n",
    "Product_Descriptions=[] # creating empty list to store the Descriptions \n",
    "\n",
    "for i in range (0,3): # running for loop using range this is runs 3 times\n",
    "    Brands=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")# locating web element of title\n",
    "    for i in Brands: # iterating over each web element of title \n",
    "        Brand=i.text         # featching the text from web element\n",
    "        Product_Brands.append(Brand)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"//html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(8)  # using time to pause the search enginer for 8 sec\n",
    "Product_Brands[0:100]\n",
    "\n",
    "for i in range (0,3): # running for loop using range this is runs 3 times\n",
    "    Prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# locating web element of title\n",
    "    for i in  Prices: # iterating over each web element of title \n",
    "        Price=i.text        # featching the text from web element\n",
    "        Product_Prices.append(Price)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"//html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(8)  # using time to pause the search enginer for 8 sec\n",
    "Product_Prices[0:100]\n",
    "\n",
    "\n",
    "for i in range (0,3): # running for loop using range this is runs 3 times\n",
    "    Descriptions=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")# locating web element of title\n",
    "    for i in  Descriptions: # iterating over each web element of title \n",
    "        Description=i.text        # featching the text from web element\n",
    "        Product_Descriptions.append(Description)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"//html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(8)  # using time to pause the search enginer for 8 sec\n",
    "Product_Descriptions[0:100]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# creating the dataframe\n",
    "sunglasses=pd.DataFrame({})\n",
    "sunglasses['BRANDS']=Product_Brands[0:100]\n",
    "sunglasses['PRODUCT DESCRIPTIONS']=Product_Descriptions[0:100]\n",
    "sunglasses['PRICES']=Product_Prices[0:100]\n",
    "sunglasses.index+=1\n",
    "sunglasses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7f0bc",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "* This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b2ffe9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "\n",
    "#Let's call the Function Definition\n",
    "\n",
    "def iphone_100_review(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<10:\n",
    "    \n",
    "        ratings=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in ratings:\n",
    "            rating.append(i.text)\n",
    "        \n",
    "        reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in reviews:\n",
    "            review_summary.append(i.text)\n",
    "        \n",
    "        full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in full_reviews:\n",
    "            full_review.append(i.text)\n",
    "        time.sleep(10)    \n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(10)\n",
    "        j+=1\n",
    "        time.sleep(10)\n",
    "\n",
    "    # Let's create a DataFrame for our data\n",
    "    iphone_review=pd.DataFrame({})\n",
    "    iphone_review['Rating']=rating\n",
    "    iphone_review['Review Summary']=review_summary\n",
    "    iphone_review['Full Reviews']=full_review\n",
    "    return iphone_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b8b36559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5  Best in the market!   \n",
       "2       5     Perfect product!   \n",
       "3       5    Worth every penny   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5   Highly recommended   \n",
       "96      5        Great product   \n",
       "97      5    Worth every penny   \n",
       "98      4          Good choice   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                         Full Reviews  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Great iPhone very snappy experience as apple k...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  What a camera .....just awesome ..you can feel...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  So far it’s been an AMAZING experience coming ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call the Calling Function\n",
    "\n",
    "iphone_100_review('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb70a4d",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "* As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d344c874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANDS</th>\n",
       "      <th>PRODUCT DESCRIPTIONS</th>\n",
       "      <th>PRICES</th>\n",
       "      <th>PRODUCT OFFERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echor</td>\n",
       "      <td>13 Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack of 3 Casual Loafer, Sneakers For Men</td>\n",
       "      <td>₹2,999</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Casual sneakers Canvas Outdoor White Shoes For...</td>\n",
       "      <td>₹1,295</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>MARION 2.0 Sneakers For Men</td>\n",
       "      <td>₹1,007</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>FUTURE RIDER PLAY ON Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹824</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LEE COOPER</td>\n",
       "      <td>Athleisure Sneakers For Men</td>\n",
       "      <td>₹3,119</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>OP-1 PWRFRAME PRONOUNCE Sneakers For Men</td>\n",
       "      <td>₹3,499</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>Monitor Welcro Black School Shoes,Running Shoe...</td>\n",
       "      <td>₹1,169</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BRANDS                               PRODUCT DESCRIPTIONS  PRICES  \\\n",
       "1           Echor                                13 Sneakers For Men    ₹399   \n",
       "2          BRUTON    Combo Pack of 3 Casual Loafer, Sneakers For Men  ₹2,999   \n",
       "3           BIRDE  Casual sneakers Canvas Outdoor White Shoes For...  ₹1,295   \n",
       "4    Robbie jones                        MARION 2.0 Sneakers For Men  ₹1,007   \n",
       "5          BRUTON              FUTURE RIDER PLAY ON Sneakers For Men    ₹398   \n",
       "..            ...                                                ...     ...   \n",
       "96           PUMA                                   Sneakers For Men    ₹824   \n",
       "97     LEE COOPER                        Athleisure Sneakers For Men  ₹3,119   \n",
       "98       Roadster           OP-1 PWRFRAME PRONOUNCE Sneakers For Men  ₹3,499   \n",
       "99          SPARX  Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹699   \n",
       "100  K- FOOTLANCE  Monitor Welcro Black School Shoes,Running Shoe...  ₹1,169   \n",
       "\n",
       "    PRODUCT OFFERS  \n",
       "1          60% off  \n",
       "2          62% off  \n",
       "3          52% off  \n",
       "4          57% off  \n",
       "5          59% off  \n",
       "..             ...  \n",
       "96         60% off  \n",
       "97         68% off  \n",
       "98         49% off  \n",
       "99         65% off  \n",
       "100        58% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#opening up flipkart.com website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "# if its asked email and phone number lets exit from that \n",
    "exit_button=driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "exit_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#  finding element for job search bar\n",
    "search_field_loc=driver.find_element_by_class_name(\"_3704LK\")#job search bar\n",
    "search_field_loc.send_keys(\"sneakers\")\n",
    "\n",
    "#clicking the search button \n",
    "search_button=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "Product_Brands=[] # creating empty list to store the Brands\n",
    "for i in range (0,3): # running for loop using range this is runs 3 times\n",
    "    Brands=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")# locating web element of title\n",
    "    for i in Brands: # iterating over each web element of title \n",
    "        Brand=i.text         # featching the text from web element\n",
    "        Product_Brands.append(Brand)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"//html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(5)  # using time to pause the search enginer for 5 sec\n",
    "Product_Brands[0:100]\n",
    "\n",
    "Product_Prices=[] # creating empty list to store the prices \n",
    "\n",
    "for i in range (0,3): # running for loop using range this is runs 3 times\n",
    "    Prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# locating web element of title\n",
    "    for i in  Prices: # iterating over each web element of title \n",
    "        Price=i.text        # featching the text from web element\n",
    "        Product_Prices.append(Price)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(8)  # using time to pause the search enginer for 8 sec\n",
    "Product_Prices[0:100]\n",
    "\n",
    "Product_Descriptions=[] # creating empty list to store the Descriptions \n",
    "\n",
    "for i in range (0,4): # running for loop using range this is runs 3 times\n",
    "    Descriptions=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")# locating web element of title\n",
    "    for i in  Descriptions: # iterating over each web element of title \n",
    "        Description=i.text        # featching the text from web element\n",
    "        Product_Descriptions.append(Description)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(8)  # using time to pause the search enginer for 8 sec\n",
    "Product_Descriptions[0:100]\n",
    "\n",
    "Product_Offers=[]# creating empty list to store the Descriptions\n",
    "\n",
    "for i in range (0,3): # running for loop using range this is runs 3 times\n",
    "    Offers=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")# locating web element of title\n",
    "    for i in  Offers: # iterating over each web element of title \n",
    "        Offer=i.text        # featching the text from web element\n",
    "        Product_Offers.append(Offer)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(8)  # using time to pause the search enginer for 8 sec\n",
    "Product_Offers[0:100]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# creating the dataframe\n",
    "sneakers=pd.DataFrame({})\n",
    "sneakers['BRANDS']=Product_Brands[0:100]\n",
    "sneakers['PRODUCT DESCRIPTIONS']=Product_Descriptions[0:100]\n",
    "sneakers['PRICES']=Product_Prices[0:100]\n",
    "sneakers['PRODUCT OFFERS']=Product_Offers[0:100]\n",
    "sneakers.index+=1\n",
    "sneakers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48434cd3",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "* Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "* And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of * the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "969f4b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND OF SHOES</th>\n",
       "      <th>SHORT SHOE DESCRIPTIONS</th>\n",
       "      <th>PRICE OF THE SHOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Solid Leather Formal Monk Shoes</td>\n",
       "      <td>Rs. 8399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Formal Loafers</td>\n",
       "      <td>Rs. 9799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Ozweego Zip Sneakers</td>\n",
       "      <td>Rs. 12316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Solid Leather Formal Oxfords</td>\n",
       "      <td>Rs. 8399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men Textured Leather Driving Shoes</td>\n",
       "      <td>Rs. 7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>KIPRUN By Decathlon</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Basketball Shoes</td>\n",
       "      <td>Rs. 7699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BRAND OF SHOES              SHORT SHOE DESCRIPTIONS  \\\n",
       "1           UNDER ARMOUR  Men Solid Leather Formal Monk Shoes   \n",
       "2                   Puma                  Men Leather Loafers   \n",
       "3           UNDER ARMOUR           Men Leather Formal Loafers   \n",
       "4                   Puma                  Men Leather Loafers   \n",
       "5                   Puma                   Men Formal Loafers   \n",
       "..                   ...                                  ...   \n",
       "96                  Nike             Men Ozweego Zip Sneakers   \n",
       "97                  Puma     Men Solid Leather Formal Oxfords   \n",
       "98                 ASICS   Men Textured Leather Driving Shoes   \n",
       "99   KIPRUN By Decathlon         Men Textured Leather Loafers   \n",
       "100               Clarks                 Men Basketball Shoes   \n",
       "\n",
       "    PRICE OF THE SHOE  \n",
       "1            Rs. 8399  \n",
       "2            Rs. 7699  \n",
       "3            Rs. 7693  \n",
       "4            Rs. 7699  \n",
       "5            Rs. 9799  \n",
       "..                ...  \n",
       "96          Rs. 12316  \n",
       "97           Rs. 8399  \n",
       "98           Rs. 7699  \n",
       "99           Rs. 7693  \n",
       "100          Rs. 7699  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "#opening up myntra.com website on automated chrome window\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "time.sleep(3) # using time to pause the search enginer for 3 sec\n",
    "\n",
    "# used to click the men at filters\n",
    "men_selector_button=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[2]/ul/li[1]/label')\n",
    "men_selector_button.click()\n",
    "time.sleep(3) # using time to pause the search enginer for 3 sec\n",
    "\n",
    "# used to click the colour at filters\n",
    "colour_selector_button=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "colour_selector_button.click()\n",
    "time.sleep(3) # using time to pause the search enginer for 3 sec\n",
    "\n",
    "# used to click the requried cost at filters\n",
    "cost_selector_button=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "cost_selector_button.click()\n",
    "time.sleep(3) # using time to pause the search enginer for 3 sec\n",
    "\n",
    "shoe_Brands=[] # creating empty list to store the Brands\n",
    "for i in range (0,3): # running for loop using range this is runs 3 times\n",
    "    Brands=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")# locating web element of title\n",
    "    for i in Brands: # iterating over each web element of title \n",
    "        Brand=i.text         # featching the text from web element\n",
    "        shoe_Brands.append(Brand)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[11]/a\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(10)  # using time to pause the search enginer for 10 sec\n",
    "shoe_Brands[0:100]\n",
    "\n",
    "shortshoe_Descriptions=[] # creating empty list to store the Descriptions \n",
    "for i in range (0,6): # running for loop using range this is runs 3 times\n",
    "    Descriptions=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")# locating web element of title\n",
    "    for i in  Descriptions: # iterating over each web element of title \n",
    "        Description=i.text        # featching the text from web element\n",
    "        shortshoe_Descriptions.append(Description)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(10)  # using time to pause the search enginer for10 sec\n",
    "shortshoe_Descriptions[0:100]\n",
    "\n",
    "shoe_Prices=[] # creating empty list to store the prices \n",
    "for i in range (0,7): # running for loop using range this is runs 3 times\n",
    "    Prices=driver.find_elements_by_xpath(\"//span[@class='product-discountedPrice']\")# locating web element of title\n",
    "    for i in  Prices: # iterating over each web element of title \n",
    "        Price=i.text        # featching the text from web element\n",
    "        shoe_Prices.append(Price)# appending data(text)into the empty list\n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[11]\")\n",
    "    next_button.click()# locationg web element of next button and then clicking on the next button\n",
    "    time.sleep(10)  # using time to pause the search enginer for10 sec\n",
    "shoe_Prices[0:100]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# creating the dataframe\n",
    "shoes=pd.DataFrame({})\n",
    "shoes['BRAND OF SHOES']=shoe_Brands[0:100]\n",
    "shoes['SHORT SHOE DESCRIPTIONS']=shortshoe_Descriptions[0:100]\n",
    "shoes['PRICE OF THE SHOE']=shoe_Prices[0:100]\n",
    "shoes.index+=1\n",
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacdbc79",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "* Enter “Laptop” in the search field and then click the search icon.\n",
    "* Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "* After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e8de000c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAPTOP TITLES</th>\n",
       "      <th>LAPTOP RATINGS</th>\n",
       "      <th>LAPTOP PRICES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram 16 Intel Evo 11th Gen i7 Thin &amp; Light ...</td>\n",
       "      <td>136</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG Gram 17 Intel Evo 11th Gen i7 Thin &amp; Light ...</td>\n",
       "      <td>162</td>\n",
       "      <td>88,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>11</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad 5 Pro 11th Gen Intel Core i7 14...</td>\n",
       "      <td>7</td>\n",
       "      <td>75,309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>118</td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LG Gram 17 Intel Evo 11th Gen i7 Thin &amp; Light ...</td>\n",
       "      <td>162</td>\n",
       "      <td>88,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>6</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS Vivobook X515JA-EJ701WS Intel Core I7-106...</td>\n",
       "      <td>10</td>\n",
       "      <td>57,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>16</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...</td>\n",
       "      <td>18</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        LAPTOP TITLES LAPTOP RATINGS  \\\n",
       "1   LG Gram 16 Intel Evo 11th Gen i7 Thin & Light ...            136   \n",
       "2   LG Gram 17 Intel Evo 11th Gen i7 Thin & Light ...            162   \n",
       "3   Samsung Galaxy Book2 Intel 12th Gen core i7 39...             11   \n",
       "4   Lenovo IdeaPad 5 Pro 11th Gen Intel Core i7 14...              7   \n",
       "5   ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...            118   \n",
       "6   LG Gram 17 Intel Evo 11th Gen i7 Thin & Light ...            162   \n",
       "7   HP Pavilion x360 11th Gen Intel Core i7 14 inc...              6   \n",
       "8   ASUS Vivobook X515JA-EJ701WS Intel Core I7-106...             10   \n",
       "9   ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...             16   \n",
       "10  ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...             18   \n",
       "\n",
       "   LAPTOP PRICES  \n",
       "1         86,990  \n",
       "2         88,490  \n",
       "3         79,990  \n",
       "4         75,309  \n",
       "5         57,490  \n",
       "6         88,490  \n",
       "7         84,990  \n",
       "8         57,290  \n",
       "9         89,990  \n",
       "10        92,990  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "#opening up amazon.com website on automated chrome window\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "#  finding element for job search bar\n",
    "search_field_loc=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")#job search bar\n",
    "search_field_loc.send_keys(\"Laptop\")\n",
    "\n",
    "#clicking the search button \n",
    "search_button=driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "search_button=driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span/a')\n",
    "search_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "laptop_titles=[] # creating empty list to store the Brands\n",
    "laptop_Ratings=[] # creating empty list to store the Descriptions \n",
    "laptop_prices=[] # creating empty list to store the prices \n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")# locating web element of title\n",
    "for i in titles: # iterating over each web element of title \n",
    "    title=i.text         # featching the text from web element\n",
    "    laptop_titles.append(title)# appending data(text)into the empty list\n",
    "laptop_titles[0:10]\n",
    "\n",
    "Ratings=driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']\")# locating web element of title\n",
    "for i in Ratings: # iterating over each web element of title \n",
    "    Rating=i.text        # featching the text from web element\n",
    "    laptop_Ratings.append(Rating)# appending data(text)into the empty list\n",
    "laptop_Ratings[0:10]\n",
    "\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")# locating web element of title\n",
    "for i in  prices: # iterating over each web element of title \n",
    "    price=i.text        # featching the text from web element\n",
    "    laptop_prices.append(price)# appending data(text)into the empty list\n",
    "laptop_prices[0:10]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# creating the dataframe\n",
    "laptops=pd.DataFrame({})\n",
    "laptops['LAPTOP TITLES']=laptop_titles[0:10]\n",
    "laptops['LAPTOP RATINGS']=laptop_Ratings[0:10]\n",
    "laptops['LAPTOP PRICES']=laptop_prices[0:10]\n",
    "laptops.index+=1\n",
    "laptops\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28490e36",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida  location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    " * This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f7c07b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAMES</th>\n",
       "      <th>COMPANIES RATING</th>\n",
       "      <th>JOB POSTED HISTORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.2</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hcl Technologies Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>3.7</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Om Software Internet Solutions Private Limited</td>\n",
       "      <td>4.5</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>3.7</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3.3</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3.5</td>\n",
       "      <td>&lt;selenium.webdriver.remote.webelement.WebEleme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     COMPANY NAMES COMPANIES RATING  \\\n",
       "1                    GENPACT India Private Limited              4.0   \n",
       "2   Optum Global Solutions (India) Private Limited              4.2   \n",
       "3                    GENPACT India Private Limited              4.0   \n",
       "4                         Hcl Technologies Limited              3.9   \n",
       "5                 EXL Services.com ( I ) Pvt. Ltd.              3.9   \n",
       "6                                            Paytm              3.7   \n",
       "7   Om Software Internet Solutions Private Limited              4.5   \n",
       "8                                            Paytm              3.7   \n",
       "9         MOTHERSONSUMI INFOTECH & DESIGNS LIMITED              3.3   \n",
       "10              Ashkom Media India Private Limited              3.5   \n",
       "\n",
       "                                   JOB POSTED HISTORY  \n",
       "1   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "2   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "3   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "4   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "5   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "6   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "7   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "8   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "9   <selenium.webdriver.remote.webelement.WebEleme...  \n",
       "10  <selenium.webdriver.remote.webelement.WebEleme...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium   # library that is used to work woth selenium\n",
    "import pandas as pd # to create datafrme\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up \n",
    "import warnings # to ignore any sort of warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import time   # use to stop search engine for few seconds\n",
    "\n",
    "# Let's first connect to the web driver \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "#opening up ambition.com website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "#  use to select jobs in the web site \n",
    "select_job=driver.find_element_by_xpath(\"//*[@id='headerWrapper']/nav/nav/a[6]\")#job search bar\n",
    "select_job.click()\n",
    "\n",
    "\n",
    "#  finding element for job search bar\n",
    "search_field_loc=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")#job search bar\n",
    "search_field_loc.send_keys(\"Data Scientist\")\n",
    "\n",
    "# after enter the keys thn used to search button \n",
    "search_button=driver.find_element_by_xpath(\"//*[@id='jobs']/div[2]/div[1]/div[1]/div/div/div/button\")#job search bar\n",
    "search_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# used to location selection \n",
    "select_location=driver.find_element_by_xpath(\"//*[@id='filters-row']/div/div/div[2]\")\n",
    "select_location.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# used to here entring in the location \n",
    "search_field_loc=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")#job search bar\n",
    "search_field_loc.send_keys(\"Noida\")\n",
    "time.sleep(3)\n",
    "\n",
    "# after entring then select the location \n",
    "select_location=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "select_location.click()\n",
    "time.sleep(3)\n",
    "\n",
    "company_names=[] # creating empty list to store the Brands\n",
    "comany_Ratings=[] # creating empty list to store the Descriptions \n",
    "job_posted =[] # creating empty list to store the prices \n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//p[@class='company body-medium']\")# locating web element of title\n",
    "for i in companies: # iterating over each web element of title \n",
    "    company=i.text         # featching the text from web element\n",
    "    company_names.append(company)# appending data(text)into the empty list\n",
    "company_names\n",
    "\n",
    "Ratings=driver.find_elements_by_xpath(\"//span[@class='body-small']\")# locating web element of title\n",
    "for i in Ratings: # iterating over each web element of title \n",
    "    Rating=i.text        # featching the text from web element\n",
    "    comany_Ratings.append(Rating)# appending data(text)into the empty list\n",
    "comany_Ratings\n",
    "\n",
    "job_posts=driver.find_elements_by_xpath(\"//span[@class='body-small-l']\")# locating web element of title\n",
    "for i in job_posts: # iterating over each web element of title \n",
    "    job_post=i.text        # featching the text from web element\n",
    "    job_posted.append(job_post)# appending data(text)into the empty list\n",
    "job_posts[0:10]# here only collacting the ten job posts in that \n",
    "\n",
    "driver.close()\n",
    "\n",
    "# creating the dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['COMPANY NAMES']=company_names\n",
    "jobs['COMPANIES RATING']=comany_Ratings\n",
    "jobs['JOB POSTED HISTORY']=job_posts[0:10]\n",
    "jobs.index+=1\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d316a2",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "* You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "28023980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAMES</th>\n",
       "      <th>TOTAL SALARY RECORD</th>\n",
       "      <th>2</th>\n",
       "      <th>AVERAGE SALARY</th>\n",
       "      <th>MINIMUM SALARY</th>\n",
       "      <th>MAXIMUM SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>1-3 yrs exp</td>\n",
       "      <td>₹ 31.8L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 65.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>based on 271 salaries</td>\n",
       "      <td>1-4 yrs exp</td>\n",
       "      <td>₹ 23.9L</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>based on 18 salaries</td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tekion</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 21.1L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 33.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>based on 119 salaries</td>\n",
       "      <td>1-4 yrs exp</td>\n",
       "      <td>₹ 20.9L</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>based on 63 salaries</td>\n",
       "      <td>1-4 yrs exp</td>\n",
       "      <td>₹ 20.6L</td>\n",
       "      <td>₹ 7.5L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>based on 56 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 20.4L</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 28.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>based on 28 salaries</td>\n",
       "      <td>1-2 yrs exp</td>\n",
       "      <td>₹ 20.1L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 85 salaries</td>\n",
       "      <td>1-4 yrs exp</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 11.4L</td>\n",
       "      <td>₹ 32.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arcesium</td>\n",
       "      <td>based on 56 salaries</td>\n",
       "      <td>1-2 yrs exp</td>\n",
       "      <td>₹ 19.3L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            COMPANY NAMES    TOTAL SALARY RECORD            2  \\\n",
       "1                                  Google   based on 33 salaries  1-3 yrs exp   \n",
       "2                   Microsoft Corporation  based on 271 salaries  1-4 yrs exp   \n",
       "3                           Goldman Sachs   based on 18 salaries    2 yrs exp   \n",
       "4                                  Tekion   based on 33 salaries  2-4 yrs exp   \n",
       "5                                  Amazon  based on 119 salaries  1-4 yrs exp   \n",
       "6                                Flipkart   based on 63 salaries  1-4 yrs exp   \n",
       "7   Servicenow Software Development India   based on 56 salaries  2-4 yrs exp   \n",
       "8                                  PayPal   based on 28 salaries  1-2 yrs exp   \n",
       "9                                 Walmart   based on 85 salaries  1-4 yrs exp   \n",
       "10                               Arcesium   based on 56 salaries  1-2 yrs exp   \n",
       "\n",
       "   AVERAGE SALARY MINIMUM SALARY MAXIMUM SALARY  \n",
       "1         ₹ 31.8L        ₹ 11.0L        ₹ 65.0L  \n",
       "2         ₹ 23.9L        ₹ 13.0L        ₹ 45.0L  \n",
       "3         ₹ 23.0L        ₹ 12.0L        ₹ 34.0L  \n",
       "4         ₹ 21.1L        ₹ 12.0L        ₹ 33.0L  \n",
       "5         ₹ 20.9L         ₹ 8.0L        ₹ 45.0L  \n",
       "6         ₹ 20.6L         ₹ 7.5L        ₹ 31.0L  \n",
       "7         ₹ 20.4L        ₹ 13.0L        ₹ 28.0L  \n",
       "8         ₹ 20.1L        ₹ 12.0L        ₹ 31.0L  \n",
       "9         ₹ 19.9L        ₹ 11.4L        ₹ 32.5L  \n",
       "10        ₹ 19.3L        ₹ 12.0L        ₹ 34.0L  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#importing all the neccessary libraries\n",
    "import selenium          #library that is used to work with selenium\n",
    "import numpy as np       #for dealing with arrays\n",
    "import pandas as pd      #to create dataframe\n",
    "from selenium import webdriver #importing webdriver module from selenium to openup automated chrome window\n",
    "import time                    #use to stop search engine for few seconds\n",
    "import warnings             #to ignore any sort of warnings\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "warnings.filterwarnings('ignore') #ignore the unnecessary warnings\n",
    "\n",
    "#Lets first connect to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\DELL\\Desktop\\data trained new\\fliprobo chrome driver\\chromedriver.exe\")\n",
    "\n",
    "#opening up ambition.com website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "driver.maximize_window()\n",
    "driver.find_element_by_xpath(\"//a[@class='link salaries']\").click()  #searching for salary based jobs\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"//input[@class='tt-input']\").send_keys(\"Data Scientist\")  #Searching for data scientist jobs\n",
    "\n",
    "#Scraping Details\n",
    "comp_names=[]\n",
    "avg_sal=[]\n",
    "min_sal=[]\n",
    "exp_req=[]\n",
    "\n",
    "comp=driver.find_elements_by_xpath(\"//div[@class='name']\")  #For scraping company names and total salary records\n",
    "for i in comp:\n",
    "    comp_names.append(i.text)\n",
    "\n",
    "avg=driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")  #For scraping average salary\n",
    "for i in avg:\n",
    "    avg_sal.append(i.text)\n",
    "Min=driver.find_elements_by_xpath(\"//div[@class='salary-values']\")  #For scraping minimum and maximum salaries\n",
    "for i in Min:\n",
    "    min_sal.append(i.text)\n",
    "exp=driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\") #For scraping experience\n",
    "for i in exp:\n",
    "    exp_req.append(i.text)\n",
    "    \n",
    "names=pd.DataFrame(comp_names,columns=['names'])\n",
    "sal=pd.DataFrame(min_sal,columns=['sal'])\n",
    "salary=sal['sal'].str.split('\\n',expand=True)\n",
    "salary.columns=['MINIMUM SALARY','MAXIMUM SALARY']\n",
    "name=names['names'].str.split('\\n',expand=True)\n",
    "name.columns=['COMPANY NAMES','TOTAL SALARY RECORD']\n",
    "ex=pd.DataFrame(exp_req,columns=['exp'])\n",
    "years=ex['exp'].str.split('\\n',expand=True)\n",
    "year=years.loc[: ,2]\n",
    "year.columns=[\"Experience\"]\n",
    "average=pd.DataFrame(avg_sal,columns=['AVERAGE SALARY'])\n",
    "Ambition=pd.concat([name,year,average,salary],axis=1)\n",
    "Ambition.index+=1\n",
    "Ambition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e96176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34b0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5695762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f6cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e65e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7611f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482a1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4c976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d5401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd858e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133279da",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bea34b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a196b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522e26d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a014ffe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a297ff7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588bda7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7179dc3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84d030",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b044c3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c3131",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68c8cae",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9ddff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a19f69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54015ad8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f51fb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59a4dd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc4032",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb708c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee04f3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147da30",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25049b16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930ba6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498c962",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b393c2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4e00c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012e4d7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a68fe6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81645658",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a8dc8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b43e2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bfce8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad1a65",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d67aa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4b1e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5179e07b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77026ac4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a226b5c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36126591",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b3b7cc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307e45c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226ec39",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c6970",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac10df49",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44170e99",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97afadf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fbf0db",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3319bcb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8d2e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45dbd2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d56d0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a12fb2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c8b71",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd4951",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d437a6b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5468d53",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c559d84",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330dbaa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5b92c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22627a8d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcadec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f69bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea27e1e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6f487",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59094b9e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a37603",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094e236",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ce6d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0452c0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5f0d7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbe5ef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a769b2f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
